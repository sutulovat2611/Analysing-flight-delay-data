{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j--uSjquVxtP"
   },
   "source": [
    "# Table of contents<a class=\"anchor\" id=\"table\"></a>\n",
    "\n",
    "* [1 Working with RDD](#1)\n",
    "* [1.1 Data Preparation and Loading](#1.1)\n",
    "* [1.1.1 Creating SparkSession & SparkContext](#OneOneOne)\n",
    "* [1.1.2 Read CSV files, Preprocessing, and final(formatted data) RDD for all files](#OneOneTwo)\n",
    "* [1.1.2.1 Flights RDD](#1.1.2.1)\n",
    "* [1.1.2.2 Airports RDD](#1.1.2.2)\n",
    "* [1.1.3 Show RDD number of columns, and number of records](#1.1.3)\n",
    "* [1.2 Dataset flights partitioning](#1.2)\n",
    "* [1.2.1 Obtain the maximum arrival time ](#1.2.1)\n",
    "* [1.2.2 Obtain the maximum minimum time ](#1.2.2)\n",
    "* [1.2.3 Perform range partitioning, and display the number of records in each partition](#1.2.3)\n",
    "* [1.3 Query RDD](#1.3)\n",
    "* [1.3.1 Collect a total number of flights for each month for all flights](#1.3.1)\n",
    "* [1.3.2 Collect the average delay for each month for all flights](#1.3.2)\n",
    "* [2 Working with DataFrames](#2)\n",
    "* [2.1 Data Preparation and Loading](#2.1)\n",
    "* [2.1.1 Define DataFrames](#2.1.1)\n",
    "* [2.1.2 Display the Scheme of DataFrames](#2.1.2)\n",
    "* [2.2.1 January Flights Events with ANC airport](#2.2.1)\n",
    "* [2.2.2 Average Arrival Delay From Origin to Destination](#2.2.2)\n",
    "* [2.2.3 Join Query with Airports DataFrame](#2.2.3)\n",
    "* [2.3 Analysis](#2.3.1)\n",
    "* [2.3.1 Relationship between day of week with mean arrival delay, total time delay, and count flights](#2.3.1)\n",
    "* [2.3.2 Display mean arrival delay each month](#2.3.2)\n",
    "* [2.3.3 Relationship between mean departure delay and mean arrival delay](#2.3.3)\n",
    "* [3 RDDs vs DataFrame vs Spark SQL](#3)\n",
    "* [3.1 RDD Operation](#3.1)\n",
    "* [3.2 DataFrame Operation](#3.1)\n",
    "* [3.3 Spark SQL Operation](#3.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pq7r4WObVxtS"
   },
   "source": [
    "\n",
    "# 1 Working with RDD<a class=\"anchor\" id=\"1\"></a>\n",
    "## 1.1 Data Preparation and Loading<a class=\"anchor\" id=\"1.1\"></a>\n",
    "### 1.1.1 Create SparkSession and SparkContext<a class=\"anchor\" id=\"OneOneOne\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2NRODj3pVxtT"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "from pyspark.sql import Window\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Import SparkContext \n",
    "from pyspark import SparkContext # Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBrnI5SJVxtU"
   },
   "source": [
    "### 1.1.2 Import CSV files and Make an RDD for all files<a class=\"anchor\" id=\"OneOneTwo\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XtpiKar7VxtV"
   },
   "outputs": [],
   "source": [
    "# local[*]: run Spark in local mode with as many working processors as logical cores on your machine\n",
    "master = \"local[*]\"\n",
    "# Giving the app name of Assignment 1 to be shown on the Spark cluster UI page\n",
    "app_name = \"Assignment 1\"\n",
    "# Setup configuration parameters for Spark\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name)\n",
    "\n",
    "# Method 1: Using SparkSession\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If1K0GfKVxtV"
   },
   "source": [
    "#### 1.1.2.1 Flights RDD <a class=\"anchor\" id=\"1.1.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BHFh-YChVxtW"
   },
   "outputs": [],
   "source": [
    "# access flights file from flights.csv\n",
    "flights_raw_rdd = sc.textFile('flight*.csv')\n",
    "# https://sparkbyexamples.com/apache-spark-rdd/spark-read-multiple-text-files-into-a-single-rdd/#directory (reference - Read all text files matching a pattern to single RDD)\n",
    "\n",
    "#take the array first index of array as a string\n",
    "#split the string into the array using comma separator\n",
    "#https://www.w3schools.com/python/ref_string_split.asp (reference)\n",
    "colNameFlights = flights_raw_rdd.take(1)[0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kJfBNetqVxtX"
   },
   "outputs": [],
   "source": [
    "flights_int_columns = ['YEAR', 'MONTH', 'DAY','DAY_OF_WEEK','FLIGHT_NUMBER']\n",
    "flights_float_columns = ['DEPARTURE_DELAY','ARRIVAL_DELAY','TAXI_OUT','ELAPSED_TIME','AIR_TIME','DISTANCE','TAXI_IN','TAXI_OUT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j2EOq4_FVxtY"
   },
   "outputs": [],
   "source": [
    "# remove header RDD\n",
    "header1 = flights_raw_rdd.first() #extract header\n",
    "flights_rdd = flights_raw_rdd.filter(lambda row: row != header1)   #filter out header\n",
    "\n",
    "# parsing RDD\n",
    "#splitting each record in each row with coma\n",
    "flights_rdd = flights_rdd.map(lambda line: line.split(','))\n",
    "\n",
    "def cast_data(line):\n",
    "    for x in range(len(line)):\n",
    "        if x == 0 or x == 1 or x == 2 or x ==3 or x == 5:\n",
    "            if line[x]:\n",
    "                line[x] = int(line[x])\n",
    "            else:\n",
    "                line[x] = 0  \n",
    "        if x == 11 or x == 12 or x == 15 or x == 16 or x == 17 or x == 19 or x ==22:\n",
    "            if line[x]:\n",
    "                line[x] = float(line[x])\n",
    "            else:\n",
    "                line[x] = 0\n",
    "    return line\n",
    "            \n",
    "#casting data \n",
    "flights_rdd = flights_rdd.map(cast_data)\n",
    "#mapping each row to a Row object \n",
    "flights_rdd = flights_rdd.map(lambda line: Row(YEAR=line[0], MONTH=line[1], DAY=line[2], DAY_OF_WEEK=line[3], AIRLINE=line[4], FLIGHT_NUMBER=int(line[5]), TAIL_NUMBER=line[6], ORIGIN_AIRPORT=line[7], DESTINATION_AIRPORT=line[8], SCHEDULED_DEPARTURE=line[9], DEPARTURE_TIME=line[10], DEPARTURE_DELAY=line[11], TAXI_OUT=line[12], WHEELS_OFF=line[13], SCHEDULED_TIME=line[14], ELAPSED_TIME= line[15], AIR_TIME=line[16], DISTANCE=line[17], WHEELS_ON=line[18], TAXI_IN=line[19], SCHEDULED_ARRIVAL=line[20], ARRIVAL_TIME=line[21], ARRIVAL_DELAY=line[22], DIVERTED=line[23], CANCELLED=line[24], CANCELLATION_REASON=line[25], AIR_SYSTEM_DELAY=line[26], SECURITY_DELAY=line[27], AIRLINE_DELAY=line[28], LATE_AIRCRAFT_DELAY=line[29], WEATHER_DELAY=line[30]))\n",
    "\n",
    "\n",
    "# Example row object\n",
    "# Row(YEAR=2015, MONTH=6, DAY=26, DAY_OF_WEEK=5, AIRLINE='EV', FLIGHT_NUMBER=4951, TAIL_NUMBER='N707EV', ORIGIN_AIRPORT='BHM', DESTINATION_AIRPORT='LGA', SCHEDULED_DEPARTURE='630', DEPARTURE_TIME='629', DEPARTURE_DELAY=-1.0, TAXI_OUT=13.0, WHEELS_OFF='642', SCHEDULED_TIME='155', ELAPSED_TIME=141.0, AIR_TIME=113.0, DISTANCE=866.0, WHEELS_ON='935', TAXI_IN=15.0, SCHEDULED_ARRIVAL='1005', ARRIVAL_TIME='950', ARRIVAL_DELAY=-15.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY='')\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-row-using-rdd-dataframe/ (reference - some information about row object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh2aQKB5VxtZ"
   },
   "source": [
    "#### 1.1.2.2 Airports RDD <a class=\"anchor\" id=\"1.1.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G5iwuTA_VxtZ"
   },
   "outputs": [],
   "source": [
    "# access airports file\n",
    "airports_raw_rdd = sc.textFile('airports.csv')\n",
    "\n",
    "colNameAirports = airports_raw_rdd.take(1)[0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AqOLUnRXVxtZ"
   },
   "outputs": [],
   "source": [
    "# remove header RDD\n",
    "header2 = airports_raw_rdd.first() #extract header\n",
    "airports_rdd = airports_raw_rdd.filter(lambda row: row != header2)   #filter out header\n",
    "\n",
    "# parsing RDD\n",
    "#splitting each record in each row with coma\n",
    "airports_rdd = airports_rdd.map(lambda line: line.split(','))\n",
    "#mapping each row to a Row object \n",
    "airports_rdd = airports_rdd.map(lambda line: Row(IATA_CODE=line[0], AIRPORT=line[1], CITY = line[2], STATE = line[3], COUNTRY=line[4], LATITUDE= line[5], LONGITUDE= line [6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T53XucvVxta"
   },
   "source": [
    "### 1.1.3 Show RDD number of columns, number of records, and number of partitions <a class=\"anchor\" id=\"1.1.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mL4nAQpFVxta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in flights:31\n",
      "Number of records in flights:582184\n",
      "Number of partitions in flights:20\n",
      "Number of columns in airports:7\n",
      "Number of partitions in airports:2\n",
      "Number of records in airports:322\n"
     ]
    }
   ],
   "source": [
    "#for flights\n",
    "print(\"Number of columns in flights:{}\".format(len(colNameFlights)))\n",
    "print(\"Number of records in flights:{}\".format(flights_rdd.count()))\n",
    "print(\"Number of partitions in flights:{}\".format(flights_rdd.getNumPartitions()))\n",
    "\n",
    "#for airports\n",
    "print(\"Number of columns in airports:{}\".format(len(colNameAirports)))\n",
    "print(\"Number of partitions in airports:{}\".format(airports_rdd.getNumPartitions()))\n",
    "print(\"Number of records in airports:{}\".format(airports_rdd.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i33yxKl7Vxta"
   },
   "source": [
    "## 1.2 Dataset Partitioning <a class=\"anchor\" id=\"1.2\"></a>\n",
    "### 1.2.1 Obtain the maximum arrival time <a class=\"anchor\" id=\"1.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RAkrv1t8Vxtb",
    "outputId": "99e1a01d-3749-448d-872f-eb0b830bb6e9"
   },
   "outputs": [],
   "source": [
    "#MAXIMUM ARRIVAL DELAY (positive value)\n",
    "arrival_delay_max_row = flights_rdd.max(key = lambda x: x['ARRIVAL_DELAY'])\n",
    "arrival_delay_max= arrival_delay_max_row['ARRIVAL_DELAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fngtg4ZtVxtc"
   },
   "source": [
    "### 1.2.2 Obtain the minimum arrival time <a class=\"anchor\" id=\"1.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kslKGyqBVxtc",
    "outputId": "7519ff0a-a4d6-45a1-d7ce-d6c34b6d7f05"
   },
   "outputs": [],
   "source": [
    "#MINIMUM ARRIVAL DELAY (could be negative value)\n",
    "arrival_delay_min_row = flights_rdd.min(key = lambda x: x['ARRIVAL_DELAY'])\n",
    "arrival_delay_min= arrival_delay_min_row['ARRIVAL_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2uAFJ43TVxtc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum delay : 1665.0\n",
      "minimum delay : -82.0\n"
     ]
    }
   ],
   "source": [
    "#Print \n",
    "print(\"maximum delay :\", arrival_delay_max)\n",
    "print(\"minimum delay :\", arrival_delay_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqOUanyKVxtc"
   },
   "source": [
    "### 1.2.3 Perform range partitioning, and display the number of records in each partition <a class=\"anchor\" id=\"1.2.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSviAqikVxtd"
   },
   "source": [
    "Highly skewed using the column of 'ARRIVAL_DELAY' for partitioning. In most flights, it is not desirable if operations are required on other columns, and it would lead to starvation in workers with less data, but prolonged processing time in workers with more data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gK22Wly2Vxtd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 20\n",
      "Partition 0: 564038 records\n",
      "Partition 1: 16568 records\n",
      "Partition 2: 1237 records\n",
      "Partition 3: 196 records\n",
      "Partition 4: 70 records\n",
      "Partition 5: 33 records\n",
      "Partition 6: 21 records\n",
      "Partition 7: 12 records\n",
      "Partition 8: 4 records\n",
      "Partition 9: 5 records\n"
     ]
    }
   ],
   "source": [
    "# print(\"The number of records in each partition are \")\n",
    "\n",
    "# determine the bin number for a single partition\n",
    "no_of_partitions = 10\n",
    "bin_size = (arrival_delay_max - arrival_delay_min) / (no_of_partitions)\n",
    "\n",
    "#create the range array\n",
    "range_arr=[]\n",
    "btm_value = arrival_delay_min\n",
    "top_value = arrival_delay_max\n",
    "for x in range(10):\n",
    "    temp_arr=[]\n",
    "    temp_arr.append(btm_value)\n",
    "    top_value = btm_value + bin_size\n",
    "    temp_arr.append(top_value)\n",
    "    btm_value=top_value\n",
    "    range_arr.append(temp_arr)\n",
    "\n",
    "\n",
    "def range_function(key):\n",
    "    for index,item in enumerate(range_arr):\n",
    "        if key >=item[0] and key <=item[1]:\n",
    "            return index\n",
    "        \n",
    "partitioned_flights_rdd = flights_rdd.map( lambda x: (x['ARRIVAL_DELAY'], 1))\n",
    "partitioned_flights_rdd = partitioned_flights_rdd.partitionBy(no_of_partitions, range_function)\n",
    "print(f\"Total partitions: {flights_rdd.getNumPartitions()}\")\n",
    "\n",
    "# glom(): Return an RDD created by coalescing all elements within each partition into a list\n",
    "partitions = partitioned_flights_rdd.glom().collect()\n",
    "for index,partition in enumerate(partitions):\n",
    "    print(f\"Partition {index}: {len(partition)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIc-mEivVxtd"
   },
   "source": [
    "## 1.3 Query RDD  <a class=\"anchor\" id=\"1.3\"></a>\n",
    "### 1.3.1 Collect a total number of flights for each month <a class=\"anchor\" id=\"1.3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Plg6cTSYVxtd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights in month 1 is 47136\n",
      "Flights in month 2 is 42798\n",
      "Flights in month 3 is 50816\n",
      "Flights in month 4 is 48810\n",
      "Flights in month 5 is 49691\n",
      "Flights in month 6 is 50256\n",
      "Flights in month 7 is 52065\n",
      "Flights in month 8 is 50524\n",
      "Flights in month 9 is 46733\n",
      "Flights in month 10 is 48680\n",
      "Flights in month 11 is 46809\n",
      "Flights in month 12 is 47866\n"
     ]
    }
   ],
   "source": [
    "# group the values by month and get the total number of flights\n",
    "flights_rdd_monthly = flights_rdd.groupBy(lambda x: x['MONTH']).map(lambda line: (line[0], len(line[1]))).collect()\n",
    "\n",
    "# loop through the values to print out the output\n",
    "for x in range(len(flights_rdd_monthly)):\n",
    "    print(\"Flights in month \" + str(flights_rdd_monthly[x][0]) + \" is \" + str(flights_rdd_monthly[x][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGHFimwBVxte"
   },
   "source": [
    "### 1.3.2 Collect the average delay for each month <a class=\"anchor\" id=\"1.3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fAOgzsWhVxte"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average delay of flights in month: 1 is 5.652155465037339\n",
      "Average delay of flights in month: 2 is 7.722627225571288\n",
      "Average delay of flights in month: 3 is 4.889286838790932\n",
      "Average delay of flights in month: 4 is 3.1355050194632246\n",
      "Average delay of flights in month: 5 is 4.644402406874485\n",
      "Average delay of flights in month: 6 is 9.534662527857371\n",
      "Average delay of flights in month: 7 is 6.701373283395755\n",
      "Average delay of flights in month: 8 is 4.652501781331645\n",
      "Average delay of flights in month: 9 is -0.8448847709327456\n",
      "Average delay of flights in month: 10 is -0.5383935907970419\n",
      "Average delay of flights in month: 11 is 0.8206114208805999\n",
      "Average delay of flights in month: 12 is 6.035244223457151\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "# getting the sum of arrival delay for each month\n",
    "flights_rdd_sum_delay = flights_rdd.map(lambda x: [x['MONTH'], x['ARRIVAL_DELAY']]).reduceByKey(add).collect()\n",
    "\n",
    "# print out the average value \n",
    "for x in range(len(flights_rdd_monthly)):\n",
    "    print(\"Average delay of flights in month: \" + str(flights_rdd_sum_delay [x][0]) + \" is \" + str(flights_rdd_sum_delay[x][1]/flights_rdd_monthly[x][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MFbmLGCVxte"
   },
   "source": [
    "# 2 Working with DataFrame <a class=\"anchor\" id=\"2\"></a>\n",
    "## 2.1. Data Preparation and Loading <a class=\"anchor\" id=\"2.1\"></a>\n",
    "### 2.1.1 Define dataframes and loading scheme<a class=\"anchor\" id=\"2.1.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WKbuOl9vVxte"
   },
   "outputs": [],
   "source": [
    "# load all flights and airports data into the dataframes\n",
    "flightsDf = spark.read.csv(\"flight*.csv\", header = True, inferSchema = True)\n",
    "airportsDf = spark.read.csv(\"airports.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IQDNg6OVxte"
   },
   "source": [
    "### 2.1.2 Display the schema of the final two dataframes<a class=\"anchor\" id=\"2.1.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zvcFv5CuVxte"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRPORT: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema of both dataframes\n",
    "flightsDf.printSchema()\n",
    "airportsDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhHyddShVxte"
   },
   "source": [
    "## 2.2. Query Analysis <a class=\"anchor\" id=\"2.2\"></a>\n",
    "### 2.2.1 January flight events with ANC airport <a class=\"anchor\" id=\"2.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OJezlIeDVxte"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+-------------------+--------+-------------+\n",
      "|MONTH|ORIGIN_AIRPORT|DESTINATION_AIRPORT|DISTANCE|ARRIVAL_DELAY|\n",
      "+-----+--------------+-------------------+--------+-------------+\n",
      "|    1|           ANC|                SEA|    1448|          -13|\n",
      "|    1|           ANC|                SEA|    1448|           -4|\n",
      "|    1|           ANC|                JNU|     571|           17|\n",
      "|    1|           ANC|                CDV|     160|           20|\n",
      "|    1|           ANC|                BET|     399|          -20|\n",
      "|    1|           ANC|                SEA|    1448|          -15|\n",
      "|    1|           ANC|                SEA|    1448|          -11|\n",
      "|    1|           ANC|                ADQ|     253|          -16|\n",
      "|    1|           ANC|                SEA|    1448|           17|\n",
      "|    1|           ANC|                BET|     399|           -9|\n",
      "|    1|           ANC|                SEA|    1448|           15|\n",
      "|    1|           ANC|                FAI|     261|           -6|\n",
      "|    1|           ANC|                JNU|     571|            2|\n",
      "|    1|           ANC|                JNU|     571|           -3|\n",
      "|    1|           ANC|                PDX|    1542|          -21|\n",
      "|    1|           ANC|                SEA|    1448|           -5|\n",
      "|    1|           ANC|                SEA|    1448|          -15|\n",
      "|    1|           ANC|                PDX|    1542|          -13|\n",
      "|    1|           ANC|                SFO|    2018|           20|\n",
      "|    1|           ANC|                FAI|     261|           56|\n",
      "+-----+--------------+-------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. Display all the flight events in January 2015 with five columns (Month, Origin Airport, Destination Airport, Distance, and Arrival Delay), where the origin airport 'ANC' and name this dataframe as janFlightEventsAncDf.\n",
    "# Get the records for January 2015\n",
    "janFlightEventsAncDfn = flightsDf.filter(col(\"YEAR\") == 2015).filter(col(\"MONTH\")==1)\n",
    "# Get the records for Origin ariport 'ANC'\n",
    "janFlightEventsAncDfn = janFlightEventsAncDfn.filter(col(\"ORIGIN_AIRPORT\")==\"ANC\")\n",
    "# Select only 5 columns\n",
    "janFlightEventsAncDfn = janFlightEventsAncDfn.select(\"MONTH\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\", \"DISTANCE\", \"ARRIVAL_DELAY\")\n",
    "# Show the result\n",
    "janFlightEventsAncDfn.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fClZO6_AVxte"
   },
   "source": [
    "### 2.2.2 Average Arrival Delay From Origin to Destination <a class=\"anchor\" id=\"2.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6Iyj_HQKVxtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|AVERAGE_DELAY      |\n",
      "+--------------+-------------------+-------------------+\n",
      "|ANC           |ADK                |-27.0              |\n",
      "|ANC           |HNL                |-20.0              |\n",
      "|ANC           |MSP                |-19.25             |\n",
      "|ANC           |BET                |-9.090909090909092 |\n",
      "|ANC           |SEA                |-6.490196078431373 |\n",
      "|ANC           |BRW                |-4.333333333333333 |\n",
      "|ANC           |OME                |-3.0               |\n",
      "|ANC           |ADQ                |-2.6666666666666665|\n",
      "|ANC           |CDV                |1.0                |\n",
      "|ANC           |OTZ                |1.25               |\n",
      "|ANC           |PHX                |2.0                |\n",
      "|ANC           |DEN                |3.3333333333333335 |\n",
      "|ANC           |PDX                |3.5                |\n",
      "|ANC           |JNU                |5.0                |\n",
      "|ANC           |LAS                |9.0                |\n",
      "|ANC           |SCC                |16.666666666666668 |\n",
      "|ANC           |SFO                |20.0               |\n",
      "|ANC           |FAI                |25.0               |\n",
      "+--------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "#From the query results on query no.1, please display a new query. Then please group by ‘ORIGIN_AIRPORT’ AND ‘DESTINATION_AIRPORT’. Add a new column and name it as ‘AVERAGE_DELAY’. This column value is the average from all ‘ARRIVAL_DELAY’ values. Then sort it based on ‘AVERAGE_DELAY’. Please name this dataframe as janFlightEventsAncAvgDf.\n",
    "# groupping by the origin airport and destination airport\n",
    "janFlightEventsAncAvgDf = janFlightEventsAncDfn.groupby('ORIGIN_AIRPORT', 'DESTINATION_AIRPORT')\n",
    "# adding a new column, which contains the average delay\n",
    "janFlightEventsAncAvgDf = janFlightEventsAncAvgDf.agg(F.avg(\"ARRIVAL_DELAY\").alias(\"AVERAGE_DELAY\"))\n",
    "#sort based on avg_delay\n",
    "janFlightEventsAncAvgDf= janFlightEventsAncAvgDf.sort(\"AVERAGE_DELAY\")\n",
    "#show the result\n",
    "janFlightEventsAncAvgDf.show(truncate= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcGv97AMVxtf"
   },
   "source": [
    "### 2.2.3 Join Query with Airports DataFrame <a class=\"anchor\" id=\"2.2.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "h3is9InMVxtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+------------------+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|     AVERAGE_DELAY|IATA_CODE|             AIRPORT|         CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+--------------+-------------------+------------------+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "|           ANC|                BRW|-4.333333333333333|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                BRW|-4.333333333333333|      BRW|Wiley Post-Will R...|       Barrow|   AK|    USA|71.28545|  -156.766|\n",
      "|           ANC|                ADK|             -27.0|      ADK|        Adak Airport|         Adak|   AK|    USA|51.87796|-176.64603|\n",
      "|           ANC|                ADK|             -27.0|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OME|              -3.0|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OME|              -3.0|      OME|        Nome Airport|         Nome|   AK|    USA| 64.5122|-165.44525|\n",
      "|           ANC|                JNU|               5.0|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                JNU|               5.0|      JNU|Juneau Internatio...|       Juneau|   AK|    USA|58.35496|-134.57628|\n",
      "|           ANC|                LAS|               9.0|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                LAS|               9.0|      LAS|McCarran Internat...|    Las Vegas|   NV|    USA|36.08036|-115.15233|\n",
      "|           ANC|                SCC|16.666666666666668|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SCC|16.666666666666668|      SCC|Deadhorse Airport...|    Deadhorse|   AK|    USA|70.19476|-148.46516|\n",
      "|           ANC|                CDV|               1.0|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                CDV|               1.0|      CDV|Merle K. (Mudhole...|      Cordova|   AK|    USA|60.49183|-145.47765|\n",
      "|           ANC|                DEN|3.3333333333333335|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                DEN|3.3333333333333335|      DEN|Denver Internatio...|       Denver|   CO|    USA|39.85841|  -104.667|\n",
      "|           ANC|                OTZ|              1.25|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OTZ|              1.25|      OTZ|Ralph Wien Memori...|     Kotzebue|   AK|    USA|66.88468|-162.59855|\n",
      "|           ANC|                SFO|              20.0|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SFO|              20.0|      SFO|San Francisco Int...|San Francisco|   CA|    USA|  37.619|-122.37484|\n",
      "+--------------+-------------------+------------------+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Join the results on query no. 2 janFlightEventsAncAvgDf and airportsDf using inner join operation. Name this dataframe as joinedSqlDf, and display it\n",
    "# joining the airports df anf the df determined in 2.2.2 based on the origin/destination airport code\n",
    "joinedSqlDf = janFlightEventsAncAvgDf.join(airportsDf , (janFlightEventsAncAvgDf[\"ORIGIN_AIRPORT\"] == airportsDf[\"IATA_CODE\"]) | (janFlightEventsAncAvgDf[\"DESTINATION_AIRPORT\"] == airportsDf[\"IATA_CODE\"]), how = 'inner' )\n",
    "\n",
    "#showing the final result\n",
    "joinedSqlDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zL5rLBrVxtf"
   },
   "source": [
    "## 2.3. Analysis <a class=\"anchor\" id=\"2.3\"></a>\n",
    "### 2.3.1 Relationship between day of week with mean arrival delay, total time delay, and count flights <a class=\"anchor\" id=\"2.3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yjUHTAieVxtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+--------------+------------+\n",
      "|DAY_OF_WEEK|  MeanArrivalDelay|TotalTimeDelay|NumOfFlights|\n",
      "+-----------+------------------+--------------+------------+\n",
      "|          4| 5.684831897201573|        490186|       87683|\n",
      "|          1| 5.883000999381335|        494478|       86317|\n",
      "|          5| 4.715112525093624|        401638|       86253|\n",
      "|          3|3.9745505431431147|        335150|       85607|\n",
      "|          2| 4.391518272706391|        363262|       84449|\n",
      "|          7| 4.299206488272548|        343498|       81422|\n",
      "|          6| 1.813841449342257|        125750|       70453|\n",
      "+-----------+------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the total number of flights events, total time delay and average of arrival delay for each day of week (‘DAY_OF_WEEK’) sorted by the value of NumOfFlights in descending order. This query represents the summary of all 2015 flights. Please discuss what you observe from this query results.\n",
    "# group by the weekday\n",
    "weekdayRelationshipDf = flightsDf.groupby('DAY_OF_WEEK')\n",
    "# get all the needed data\n",
    "weekdayRelationshipDf = weekdayRelationshipDf.agg(F.avg(\"ARRIVAL_DELAY\").alias(\"MeanArrivalDelay\"), F.sum(\"ARRIVAL_DELAY\").alias(\"TotalTimeDelay\"), F.count('DAY_OF_WEEK').alias('NumOfFlights'))\n",
    "# descenfing order by the num of flights\n",
    "weekdayRelationshipDf = weekdayRelationshipDf.sort('NumOfFlights', ascending=False)\n",
    "# sort the data by Num of flights in descending order\n",
    "weekdayRelationshipDf.show()\n",
    "\n",
    "# Observation: from the obtained result it may be observed that monday and thursday are the weekdays that have the highest\n",
    "# number of flights, whereas saturday and sunday, the weekend, have the lowest. It may be also noticed that the\n",
    "# higher is the numer of flights a day, the higher is the total time delay and, thus, the mean arrival delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2D1YjF9Vxtf"
   },
   "source": [
    "### 2.3.2 Display mean arrival delay each month <a class=\"anchor\" id=\"2.3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o7fccwwsVxtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------+------------+\n",
      "|MONTH|   MeanArrivalDelay|TotalTimeDelay|NumOfFlights|\n",
      "+-----+-------------------+--------------+------------+\n",
      "|    2|  8.123906203913085|        330513|       42798|\n",
      "|    9|-0.8498676252179341|        -39484|       46733|\n",
      "|   11| 0.8313745860658399|         38412|       46809|\n",
      "|    1|  5.804357298474946|        266420|       47136|\n",
      "|   12|   6.15837046195826|        288883|       47866|\n",
      "|   10| -0.541989784312509|        -26209|       48680|\n",
      "|    4|  3.173803944339603|        153044|       48810|\n",
      "|    5| 4.7121097658084405|        230785|       49691|\n",
      "|    6|  9.747630090727856|        479174|       50256|\n",
      "|    8|  4.713893233866763|        235063|       50524|\n",
      "|    3|  5.011173860427592|        248454|       50816|\n",
      "|    7|  6.786093552465234|        348907|       52065|\n",
      "+-----+-------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the average of arrival delay, total time delay, and total number of flight events for each month (‘MONTH’) sorted by MeanArrivalDelay in ascending order (default). Please discuss what you observe from this query results.\n",
    "# group by the month\n",
    "monthRelationshipDf = flightsDf.groupby('MONTH')\n",
    "# get all the needed data\n",
    "monthRelationshipDf = monthRelationshipDf.agg(F.avg(\"ARRIVAL_DELAY\").alias(\"MeanArrivalDelay\"), F.sum(\"ARRIVAL_DELAY\").alias(\"TotalTimeDelay\"), F.count('MONTH').alias('NumOfFlights'))\n",
    "# descenfing order by the num of flights\n",
    "monthRelationshipDf = monthRelationshipDf.sort('NumOfFlights')\n",
    "# sort the data by Num of flights in descending order\n",
    "monthRelationshipDf.show()\n",
    "\n",
    "#Observation: from the obtained result it may be observed that July is the month that has the most flights, whereas \n",
    "# february is the one with the least. The total time delay does not significantly correlate with the number of flights\n",
    "# in thid case, since both july and feb has approximately the same total time delay number, with almost 10k difference \n",
    "# between the number of flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL4YaOAmVxtf"
   },
   "source": [
    "### 2.3.3 Relationship between mean departure delay and mean arrival delay <a class=\"anchor\" id=\"2.3.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l-QGLFIEVxtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-------------------+--------------+------------+\n",
      "|MONTH|     MeanDeptDelay|   MeanArrivalDelay|TotalTimeDelay|NumOfFlights|\n",
      "+-----+------------------+-------------------+--------------+------------+\n",
      "|    6|  13.9730063585922|  9.747630090727856|        479174|       50256|\n",
      "|   12|11.821651454043728|   6.15837046195826|        288883|       47866|\n",
      "|    7|11.708608758020432|  6.786093552465234|        348907|       52065|\n",
      "|    2|11.620796080832823|  8.123906203913085|        330513|       42798|\n",
      "|    8|10.086906141367324|  4.713893233866763|        235063|       50524|\n",
      "|    1|  9.75401499511029|  5.804357298474946|        266420|       47136|\n",
      "|    3| 9.718308159530178|  5.011173860427592|        248454|       50816|\n",
      "|    5| 9.550310180006102| 4.7121097658084405|        230785|       49691|\n",
      "|    4| 7.737554783759199|  3.173803944339603|        153044|       48810|\n",
      "|   11| 6.630585898709037| 0.8313745860658399|         38412|       46809|\n",
      "|   10| 5.243436261558784| -0.541989784312509|        -26209|       48680|\n",
      "|    9| 4.728506981740065|-0.8498676252179341|        -39484|       46733|\n",
      "+-----+------------------+-------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the mean departure delay (MeanDeptDelay) and mean arrival delay (MeanArrivalDelay) for each month (‘MONTH’) sorted by MeanDeptDelay in descending order. Please discuss the relationship between two columns: Mean Departure Delay and Mean Arrival Delay.\n",
    "# group by the weekday\n",
    "deptRelationshipDf = flightsDf.groupby('MONTH')\n",
    "# get all the needed data\n",
    "deptRelationshipDf = deptRelationshipDf.agg(F.avg(\"DEPARTURE_DELAY\").alias(\"MeanDeptDelay\"), F.avg(\"ARRIVAL_DELAY\").alias(\"MeanArrivalDelay\"), F.sum(\"ARRIVAL_DELAY\").alias(\"TotalTimeDelay\"), F.count('MONTH').alias('NumOfFlights'))\n",
    "# descending order by the num of flights\n",
    "deptRelationshipDf = deptRelationshipDf.sort('MeanDeptDelay', ascending=False)\n",
    "# sort the data by Num of flights in descending order\n",
    "deptRelationshipDf.show()\n",
    "\n",
    "#Observation: comparing the MeanDeptDelay and MeanArrivalDelay values, it may be observed that the higher the MeanDeptDelay is\n",
    "# the higher the MeanArrivalDelay is as well, excluding some exceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTKR3olIVxtf"
   },
   "source": [
    "# 3 RDDs vs DataFrame vs Spark SQL <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "\n",
    "Implement the following queries using RDDs, DataFrames and SparkSQL separately. Log the time taken for each query in each approach using the “%%time” built-in magic command in Jupyter Notebook and discuss the computational performance difference of these 3 approaches.\n",
    "\n",
    "<strong>Find the MONTH and DAY_OF_WEEK, number of flights, and average delay where TAIL_NUMBER = ‘N407AS’. Note number of flights and average delay should be aggregated separately. The number of flights and average delay should be grouped by both MONTH and DAYS_OF_WEEK.</strong>\n",
    "\n",
    "## 3.1 RDD Operation<a class=\"anchor\" id=\"3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oXa5hpgvVxtg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|MONTH|DAY_OF_WEEK|TAIL_NUMBER|NumOfFlights|MeanDeptDelay|MeanArrivalDelay \n",
      "   3|          3|     N407AS|           1|        28.0|         3.0\n",
      "   9|          5|     N407AS|           1|        4.0|         5.0\n",
      "   12|          2|     N407AS|           2|        1.0|         -11.5\n",
      "   1|          5|     N407AS|           2|        -6.0|         -21.0\n",
      "   6|          4|     N407AS|           1|        -6.0|         -15.0\n",
      "   1|          1|     N407AS|           1|        4.0|         -6.0\n",
      "   6|          1|     N407AS|           4|        4.5|         7.0\n",
      "   2|          5|     N407AS|           1|        -11.0|         -31.0\n",
      "   11|          5|     N407AS|           1|        -4.0|         12.0\n",
      "   11|          1|     N407AS|           1|        57.0|         35.0\n",
      "   8|          5|     N407AS|           3|        1.6666666666666667|         -10.0\n",
      "   5|          6|     N407AS|           2|        0.5|         -3.0\n",
      "   11|          4|     N407AS|           2|        -7.5|         -1.0\n",
      "   10|          4|     N407AS|           1|        -11.0|         -6.0\n",
      "   4|          2|     N407AS|           1|        -2.0|         6.0\n",
      "   4|          3|     N407AS|           1|        -4.0|         -7.0\n",
      "   8|          3|     N407AS|           1|        2.0|         -4.0\n",
      "   8|          4|     N407AS|           1|        -7.0|         -5.0\n",
      "   5|          7|     N407AS|           3|        4.666666666666667|         -7.666666666666667\n",
      "   7|          1|     N407AS|           1|        -3.0|         -1.0\n",
      "   6|          2|     N407AS|           1|        33.0|         35.0\n",
      "   9|          3|     N407AS|           5|        -5.2|         -14.6\n",
      "   5|          3|     N407AS|           1|        -6.0|         30.0\n",
      "   1|          3|     N407AS|           1|        -7.0|         -27.0\n",
      "   12|          1|     N407AS|           1|        -5.0|         -1.0\n",
      "   2|          7|     N407AS|           2|        -7.0|         6.5\n",
      "   3|          4|     N407AS|           1|        1.0|         2.0\n",
      "   12|          5|     N407AS|           2|        -4.5|         2.0\n",
      "   9|          1|     N407AS|           2|        -5.5|         -15.5\n",
      "   7|          3|     N407AS|           3|        -0.3333333333333333|         -5.333333333333333\n",
      "   5|          5|     N407AS|           1|        17.0|         6.0\n",
      "   11|          2|     N407AS|           1|        -9.0|         -23.0\n",
      "   4|          7|     N407AS|           1|        -8.0|         -22.0\n",
      "   12|          4|     N407AS|           1|        2.0|         6.0\n",
      "   3|          1|     N407AS|           1|        40.0|         29.0\n",
      "   7|          4|     N407AS|           2|        -2.0|         -4.0\n",
      "   1|          2|     N407AS|           2|        12.5|         17.5\n",
      "   8|          2|     N407AS|           2|        -4.0|         -11.0\n",
      "   11|          7|     N407AS|           3|        -5.0|         -4.0\n",
      "   7|          7|     N407AS|           5|        15.8|         15.2\n",
      "   5|          1|     N407AS|           3|        2.0|         4.666666666666667\n",
      "   2|          4|     N407AS|           2|        -8.5|         -11.0\n",
      "   8|          7|     N407AS|           2|        66.5|         60.5\n",
      "   2|          1|     N407AS|           2|        -4.0|         -2.5\n",
      "   10|          5|     N407AS|           3|        -6.333333333333333|         -3.6666666666666665\n",
      "   3|          6|     N407AS|           1|        -1.0|         -3.0\n",
      "   10|          1|     N407AS|           2|        12.5|         15.5\n",
      "   12|          7|     N407AS|           2|        -2.0|         -1.0\n",
      "   9|          4|     N407AS|           3|        -8.333333333333334|         -10.666666666666666\n",
      "   4|          4|     N407AS|           3|        1.6666666666666667|         -0.6666666666666666\n",
      "   2|          2|     N407AS|           2|        -3.5|         -9.5\n",
      "   8|          1|     N407AS|           2|        -14.0|         -13.0\n",
      "   5|          2|     N407AS|           5|        6.0|         0.8\n",
      "   1|          6|     N407AS|           3|        8.666666666666666|         4.333333333333333\n",
      "   4|          1|     N407AS|           1|        -1.0|         0.0\n",
      "   8|          6|     N407AS|           2|        -2.0|         -5.0\n",
      "   4|          6|     N407AS|           1|        1.0|         -20.0\n",
      "   3|          2|     N407AS|           2|        -5.5|         -28.0\n",
      "   12|          3|     N407AS|           2|        1.5|         18.5\n",
      "   6|          6|     N407AS|           3|        -2.0|         -7.666666666666667\n",
      "   3|          5|     N407AS|           3|        5.666666666666667|         6.666666666666667\n",
      "   7|          5|     N407AS|           1|        9.0|         -4.0\n",
      "   6|          3|     N407AS|           3|        -5.0|         -10.666666666666666\n",
      "   9|          2|     N407AS|           1|        8.0|         -10.0\n",
      "   10|          3|     N407AS|           2|        0.0|         1.0\n",
      "   2|          3|     N407AS|           2|        -12.5|         -11.5\n",
      "CPU times: user 84.8 ms, sys: 9.07 ms, total: 93.8 ms\n",
      "Wall time: 59.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Find and display the MONTH and DAY_OF_WEEK, number of flights, average departure delay, and average arrival delay, where TAIL_NUMBER = ‘N407AS’. Note number of flights, average departure delay, and average arrival delay should be aggregated separately. The query should be grouped by MONTH, DAY_OF_WEEK, and TAIL_NUMBER.\n",
    "\n",
    "#get data only for tail number = ‘N407AS’\n",
    "rdd_data = flights_rdd.filter(lambda line: line['TAIL_NUMBER']==\"N407AS\")\n",
    "\n",
    "\n",
    "# group by the weekday, month and tail number and get the total number of flights per month + weekday\n",
    "rdd_data_total_flights = rdd_data.groupBy(lambda x: (x['MONTH'], x['DAY_OF_WEEK'], x['TAIL_NUMBER'])).map(lambda line: (line[0], len(line[1]))).collect()\n",
    "# get the average arrival delay for each month + weekday\n",
    "rdd_data_arrival= rdd_data.map(lambda x: [(x['MONTH'], x['DAY_OF_WEEK'], x['TAIL_NUMBER']), x['ARRIVAL_DELAY']]).reduceByKey(add).collect()\n",
    "# get the average departure delay for each month + weekday\n",
    "rdd_data_dept = rdd_data.map(lambda x: [(x['MONTH'], x['DAY_OF_WEEK'], x['TAIL_NUMBER']), x['DEPARTURE_DELAY']]).reduceByKey(add).collect()\n",
    "\n",
    "# print out the data\n",
    "print(\"|MONTH|DAY_OF_WEEK|TAIL_NUMBER|NumOfFlights|MeanDeptDelay|MeanArrivalDelay \")\n",
    "for x in range(len(rdd_data_total_flights)):\n",
    "    print(\"   \" + str(rdd_data_total_flights[x][0][0])+\"|          \"+str(rdd_data_total_flights[x][0][1])+\"|     \"+str(rdd_data_arrival[x][0][2])+\"|           \"+str(rdd_data_total_flights[x][1])+\"|        \"+str(rdd_data_dept[x][1]/rdd_data_total_flights[x][1])+\"|         \"+str(rdd_data_arrival[x][1]/rdd_data_total_flights[x][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoWUSLBXVxtg"
   },
   "source": [
    "## 3.2 DataFrame Operation<a class=\"anchor\" id=\"3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EnjfyGiiVxtg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+------------+-----------------+-----------------+\n",
      "|MONTH|DAY_OF_WEEK|TAIL_NUMBER|NumOfFlights|    MeanDeptDelay| MeanArrivalDelay|\n",
      "+-----+-----------+-----------+------------+-----------------+-----------------+\n",
      "|    1|          1|     N407AS|           1|              4.0|             -6.0|\n",
      "|    1|          2|     N407AS|           2|             12.5|             17.5|\n",
      "|    1|          3|     N407AS|           1|             -7.0|            -27.0|\n",
      "|    1|          5|     N407AS|           2|             -6.0|            -21.0|\n",
      "|    1|          6|     N407AS|           3|8.666666666666666|4.333333333333333|\n",
      "|    2|          1|     N407AS|           2|             -4.0|             -2.5|\n",
      "|    2|          2|     N407AS|           2|             -3.5|             -9.5|\n",
      "|    2|          3|     N407AS|           2|            -12.5|            -11.5|\n",
      "|    2|          4|     N407AS|           2|             -8.5|            -11.0|\n",
      "|    2|          5|     N407AS|           1|            -11.0|            -31.0|\n",
      "|    2|          7|     N407AS|           2|             -7.0|              6.5|\n",
      "|    3|          1|     N407AS|           1|             40.0|             29.0|\n",
      "|    3|          2|     N407AS|           2|             -5.5|            -28.0|\n",
      "|    3|          3|     N407AS|           1|             28.0|              3.0|\n",
      "|    3|          4|     N407AS|           1|              1.0|              2.0|\n",
      "|    3|          5|     N407AS|           3|5.666666666666667|6.666666666666667|\n",
      "|    3|          6|     N407AS|           1|             -1.0|             -3.0|\n",
      "|    4|          1|     N407AS|           1|             -1.0|              0.0|\n",
      "|    4|          2|     N407AS|           1|             -2.0|              6.0|\n",
      "|    4|          3|     N407AS|           1|             -4.0|             -7.0|\n",
      "+-----+-----------+-----------+------------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 8.77 ms, sys: 0 ns, total: 8.77 ms\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-groupby-explained-with-example/ (reference - GroupBy examples for dataframe)\n",
    "\n",
    "#get data only for tail number = ‘N407AS’\n",
    "df_data = flightsDf.filter((F.col(\"TAIL_NUMBER\") == \"N407AS\"))\n",
    "\n",
    "# group by the weekday, month and tail number\n",
    "df_data = df_data.groupby('MONTH', 'DAY_OF_WEEK', 'TAIL_NUMBER')\n",
    "\n",
    "# get all the needed data\n",
    "df_data = df_data.agg( F.count('MONTH').alias('NumOfFlights'), F.avg(\"DEPARTURE_DELAY\").alias(\"MeanDeptDelay\"), F.avg(\"ARRIVAL_DELAY\").alias(\"MeanArrivalDelay\"))\n",
    "\n",
    "# represent the data sorting by month and weekday\n",
    "df_data = df_data.sort('MONTH', 'DAY_OF_WEEK')\n",
    "df_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJn0s0gZVxtg"
   },
   "source": [
    "## 3.3 Spark SQL OPERATION<a class=\"anchor\" id=\"3.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gMqYqufBVxtg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+------------+-----------------+-----------------+\n",
      "|MONTH|DAY_OF_WEEK|TAIL_NUMBER|NumOfFlights|    MeanDeptDelay| MeanArrivalDelay|\n",
      "+-----+-----------+-----------+------------+-----------------+-----------------+\n",
      "|    1|          1|     N407AS|           1|              4.0|             -6.0|\n",
      "|    1|          2|     N407AS|           2|             12.5|             17.5|\n",
      "|    1|          3|     N407AS|           1|             -7.0|            -27.0|\n",
      "|    1|          5|     N407AS|           2|             -6.0|            -21.0|\n",
      "|    1|          6|     N407AS|           3|8.666666666666666|4.333333333333333|\n",
      "|    2|          1|     N407AS|           2|             -4.0|             -2.5|\n",
      "|    2|          2|     N407AS|           2|             -3.5|             -9.5|\n",
      "|    2|          3|     N407AS|           2|            -12.5|            -11.5|\n",
      "|    2|          4|     N407AS|           2|             -8.5|            -11.0|\n",
      "|    2|          5|     N407AS|           1|            -11.0|            -31.0|\n",
      "|    2|          7|     N407AS|           2|             -7.0|              6.5|\n",
      "|    3|          1|     N407AS|           1|             40.0|             29.0|\n",
      "|    3|          2|     N407AS|           2|             -5.5|            -28.0|\n",
      "|    3|          3|     N407AS|           1|             28.0|              3.0|\n",
      "|    3|          4|     N407AS|           1|              1.0|              2.0|\n",
      "|    3|          5|     N407AS|           3|5.666666666666667|6.666666666666667|\n",
      "|    3|          6|     N407AS|           1|             -1.0|             -3.0|\n",
      "|    4|          1|     N407AS|           1|             -1.0|              0.0|\n",
      "|    4|          2|     N407AS|           1|             -2.0|              6.0|\n",
      "|    4|          3|     N407AS|           1|             -4.0|             -7.0|\n",
      "+-----+-----------+-----------+------------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.14 ms, sys: 29 µs, total: 2.17 ms\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Views from Dataframes\n",
    "flightsDf.createOrReplaceTempView(\"sql_flights\")\n",
    "\n",
    "sql_data= spark.sql('''\n",
    "  SELECT MONTH, DAY_OF_WEEK, TAIL_NUMBER, count(MONTH) as NumOfFlights , AVG(DEPARTURE_DELAY) as MeanDeptDelay, AVG(ARRIVAL_DELAY) as MeanArrivalDelay\n",
    "  FROM sql_flights \n",
    "  WHERE TAIL_NUMBER = 'N407AS'\n",
    "  GROUP BY MONTH, DAY_OF_WEEK, TAIL_NUMBER\n",
    "  ORDER BY MONTH, DAY_OF_WEEK\n",
    "''')\n",
    "\n",
    "#represent the data\n",
    "sql_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational time of the Spark SQL Operation (2.21ms) is significantly lower than the one of DataFrame Operation (6.97ms) \n",
    "and the one of the RDD operation (91.5ms). The DataFrame is faster than the RDD operations, since it provides an API to perform \n",
    "aggregation operations. Moreover, DataFrame has an inbuilt optimization, whereas the RDD does not have one. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1-Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
